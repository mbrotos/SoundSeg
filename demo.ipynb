{"cells":[{"cell_type":"markdown","metadata":{"id":"zXc2NNaffrNe"},"source":["**Table of contents**<a id='toc0_'></a>    \n","- [Singing Voice Separation by U-Net](#toc1_)    \n","    - [Data Loading](#toc1_1_1_)    \n","      - [Song mixutre and vocal example](#toc1_1_1_1_)    \n","    - [Preprocessing](#toc1_1_2_)    \n","      - [Visualize the data](#toc1_1_2_1_)    \n","    - [Run unit tests](#toc1_1_3_)    \n","    - [Define Model Architecture](#toc1_1_4_)    \n","    - [Build the model](#toc1_1_5_)    \n","    - [Define datasets](#toc1_1_6_)    \n","    - [Train the model](#toc1_1_7_)    \n","    - [Evaluate the model](#toc1_1_8_)    \n","      - [Test voice seperation](#toc1_1_8_1_)    \n","      - [MIR_Eval](#toc1_1_8_2_)    \n","    - [Comparing data normalization techniques](#toc1_1_9_)    \n","\n","<!-- vscode-jupyter-toc-config\n","\tnumbering=false\n","\tanchor=true\n","\tflat=false\n","\tminLevel=1\n","\tmaxLevel=6\n","\t/vscode-jupyter-toc-config -->\n","<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"]},{"cell_type":"markdown","metadata":{"id":"h-vTtTWOfrNh"},"source":["# <a id='toc1_'></a>[Singing Voice Separation by U-Net](#toc0_)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2PuRNYOqfrNi","executionInfo":{"status":"ok","timestamp":1702392495777,"user_tz":300,"elapsed":5,"user":{"displayName":"Adam Sorrenti","userId":"08015701831222800572"}},"outputId":"cc5347ff-190d-4b9b-f3b0-0d063501661f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on CoLab\n"]}],"source":["IN_COLAB = False\n","if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    IN_COLAB = True\n","    # from google.colab import drive\n","    # drive.mount('/content/drive')\n","    # %cd drive/MyDrive/Adam_Sorrenti_500903848_Voice_Separation_Project/\n","    # !pip install -r requirements.txt\n","\n","else:\n","    print('Not running on CoLab')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8OI3EtugfrNj","executionInfo":{"status":"ok","timestamp":1702392506591,"user_tz":300,"elapsed":10817,"user":{"displayName":"Adam Sorrenti","userId":"08015701831222800572"}}},"outputs":[],"source":["import os\n","import librosa\n","import IPython.display as ipd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from scipy import stats"]},{"cell_type":"markdown","metadata":{"id":"oJSurqeMfrNj"},"source":["### <a id='toc1_1_1_'></a>[Data Loading](#toc0_)"]},{"cell_type":"code","source":["! gdown 1VyYz0prSLgvw_nbp-UpUZEo3DERgQM_n  && tar -xvf SoundSeg.tar && rm SoundSeg.tar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AM5uP9l-f42t","executionInfo":{"status":"ok","timestamp":1702392652696,"user_tz":300,"elapsed":2107,"user":{"displayName":"Adam Sorrenti","userId":"08015701831222800572"}},"outputId":"b43a9912-d233-4678-e94d-832bf1573cdd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1VyYz0prSLgvw_nbp-UpUZEo3DERgQM_n\n","To: /content/SoundSeg.tar\n","\r  0% 0.00/69.6k [00:00<?, ?B/s]\r100% 69.6k/69.6k [00:00<00:00, 107MB/s]\n","SoundSeg/\n","SoundSeg/augmentations.py\n","SoundSeg/config.py\n","SoundSeg/data/\n","SoundSeg/data/README.md\n","SoundSeg/dataload.py\n","SoundSeg/dataset_prep.py\n","SoundSeg/evaluate.py\n","SoundSeg/model.py\n","SoundSeg/models/\n","SoundSeg/models/.gitkeep\n","SoundSeg/preprocessing.py\n","SoundSeg/README.md\n","SoundSeg/requirements.txt\n","SoundSeg/run_eval.py\n","SoundSeg/run_train.py\n","SoundSeg/scaler.py\n","SoundSeg/test_audio_processing.py\n","SoundSeg/train.py\n","SoundSeg/train.sh\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCIudqQ9frNk","executionInfo":{"status":"ok","timestamp":1702392963426,"user_tz":300,"elapsed":290405,"user":{"displayName":"Adam Sorrenti","userId":"08015701831222800572"}},"outputId":"951d6ad6-3bca-448b-b38b-95bdc2bd79bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1R2AYsUQbmbgLuNUlBlLj1l0PPga9YaC8\n","To: /content/processed_data.tar\n","100% 15.5G/15.5G [02:34<00:00, 100MB/s]\n","mix_mags_test_512x128.npy\n","mix_mags_train_512x128.npy\n","mix_phases_test_512x128.npy\n","mix_phases_train_512x128.npy\n","vocal_mags_test_512x128.npy\n","vocal_mags_train_512x128.npy\n","vocal_masks_test_512x128.npy\n","vocal_masks_train_512x128.npy\n"]}],"source":["! gdown 1R2AYsUQbmbgLuNUlBlLj1l0PPga9YaC8 && tar -xvf processed_data.tar && rm processed_data.tar && mkdir SoundSeg/processed_data && mv *.npy SoundSeg/processed_data"]},{"cell_type":"markdown","metadata":{"id":"B8e_1f8cfrNk"},"source":["#### <a id='toc1_1_1_1_'></a>[Song mixutre and vocal example](#toc0_)"]},{"cell_type":"code","source":[],"metadata":{"id":"536YBpl_iYZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZQxw_4ifrNk"},"source":["### <a id='toc1_1_2_'></a>[Preprocessing](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c80cu85NfrNl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"C6AFg_PCfrNl"},"source":["#### <a id='toc1_1_2_1_'></a>[Visualize the data](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQoPH_iQfrNl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"BavM7aXzfrNl"},"source":["### <a id='toc1_1_3_'></a>[Run unit tests](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ex7NzjQZfrNl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xwmlqLhFfrNl"},"source":["### <a id='toc1_1_4_'></a>[Define Model Architecture](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0DgJpmGfrNm"},"outputs":[],"source":["import tensorflow as tf\n","from keras.layers import Activation, Conv2D, BatchNormalization, Conv2DTranspose, Concatenate, MaxPooling2D, Input, Conv1D, Normalization\n","\n","def get_model(img_size, num_classes=1):\n","    inputs = Input(shape=img_size + (1,))\n","\n","    conv1 = Conv2D(64, 3, strides=1, padding=\"same\")(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Activation(\"relu\")(conv1)\n","\n","    conv2 = Conv2D(64, 3, strides=1, padding=\"same\")(conv1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Activation(\"relu\")(conv2)\n","\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(128, 3, strides=1, padding=\"same\")(pool1)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Activation(\"relu\")(conv3)\n","\n","    conv4 = Conv2D(128, 3, strides=1, padding=\"same\")(conv3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Activation(\"relu\")(conv4)\n","\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = Conv2D(256, 3, strides=1, padding=\"same\")(pool2)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Activation(\"relu\")(conv5)\n","\n","    conv6 = Conv2D(256, 3, strides=1, padding=\"same\")(conv5)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Activation(\"relu\")(conv6)\n","\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv6)\n","\n","    conv7 = Conv2D(512, 3, strides=1, padding=\"same\")(pool3)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Activation(\"relu\")(conv7)\n","\n","    conv8 = Conv2D(512, 3, strides=1, padding=\"same\")(conv7)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Activation(\"relu\")(conv8)\n","\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv8)\n","\n","    conv9 = Conv2D(1024, 3, strides=1, padding=\"same\")(pool4)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Activation(\"relu\")(conv9)\n","\n","    conv10 = Conv2D(1024, 3, strides=1, padding=\"same\")(conv9)\n","    conv10 = BatchNormalization()(conv10)\n","    conv10 = Activation(\"relu\")(conv10)\n","\n","    up1 = Conv2DTranspose(512, 2, strides=2, padding=\"same\")(conv10)\n","    up1 = Concatenate()([up1, conv8])\n","\n","    upconv1 = Conv2D(512, 3, strides=1, padding=\"same\")(up1)\n","    upconv1 = BatchNormalization()(upconv1)\n","    upconv1 = Activation(\"relu\")(upconv1)\n","\n","    upconv2 = Conv2D(512, 3, strides=1, padding=\"same\")(upconv1)\n","    upconv2 = BatchNormalization()(upconv2)\n","    upconv2 = Activation(\"relu\")(upconv2)\n","\n","    up2 = Conv2DTranspose(256, 2, strides=2, padding=\"same\")(upconv2)\n","    up2 = Concatenate()([up2, conv6])\n","\n","    upconv3 = Conv2D(256, 3, strides=1, padding=\"same\")(up2)\n","    upconv3 = BatchNormalization()(upconv3)\n","    upconv3 = Activation(\"relu\")(upconv3)\n","\n","    upconv4 = Conv2D(256, 3, strides=1, padding=\"same\")(upconv3)\n","    upconv4 = BatchNormalization()(upconv4)\n","    upconv4 = Activation(\"relu\")(upconv4)\n","\n","    up3 = Conv2DTranspose(128, 2, strides=2, padding=\"same\")(upconv4)\n","    up3 = Concatenate()([up3, conv4])\n","\n","    upconv5 = Conv2D(128, 3, strides=1, padding=\"same\")(up3)\n","    upconv5 = BatchNormalization()(upconv5)\n","    upconv5 = Activation(\"relu\")(upconv5)\n","\n","    upconv6 = Conv2D(128, 3, strides=1, padding=\"same\")(upconv5)\n","    upconv6 = BatchNormalization()(upconv6)\n","    upconv6 = Activation(\"relu\")(upconv6)\n","\n","    up4 = Conv2DTranspose(64, 2, strides=2, padding=\"same\")(upconv6)\n","    up4 = Concatenate()([up4, conv2])\n","\n","    upconv7 = Conv2D(64, 3, strides=1, padding=\"same\")(up4)\n","    upconv7 = BatchNormalization()(upconv7)\n","    upconv7 = Activation(\"relu\")(upconv7)\n","\n","    upconv8 = Conv2D(64, 3, strides=1, padding=\"same\")(upconv7)\n","    upconv8 = BatchNormalization()(upconv8)\n","    upconv8 = Activation(\"relu\")(upconv8)\n","\n","    output = Conv1D(num_classes, 1, activation=\"linear\")(upconv8)\n","\n","    # Define the model\n","    model = tf.keras.Model(inputs, output)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"F-X8KnT_frNm"},"source":["### <a id='toc1_1_5_'></a>[Build the model](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZcW8DRsfrNm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HZouY69PfrNm"},"source":["### <a id='toc1_1_6_'></a>[Define datasets](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tliCGkG0frNm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6q6i5kLefrNm"},"source":["### <a id='toc1_1_7_'></a>[Train the model](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zwOW4PaRfrNm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"G5l_dZMFfrNn"},"source":["### <a id='toc1_1_8_'></a>[Evaluate the model](#toc0_)"]},{"cell_type":"markdown","metadata":{"id":"8xGc0CBmfrNn"},"source":["#### <a id='toc1_1_8_1_'></a>[Test voice seperation](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9NHtFDifrNn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZA2EKpSifrNn"},"source":["#### <a id='toc1_1_8_2_'></a>[MIR_Eval](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZBaoPqXfrNn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"NVD_MELffrNn"},"source":["### <a id='toc1_1_9_'></a>[Comparing data normalization techniques](#toc0_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"98DcsBTcfrNn"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"dl","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}