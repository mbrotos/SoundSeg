@misc{ronneberger2015unet,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{musdb18,
  author       = {Rafii, Zafar and
                  Liutkus, Antoine and
                  Fabian-Robert St{\"o}ter and
                  Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {The {MUSDB18} corpus for music separation},
  month        = dec,
  year         = 2017,
  doi          = {10.5281/zenodo.1117372},
  url          = {https://doi.org/10.5281/zenodo.1117372}
}

@article{stoller2018wave,
  title={Wave-u-net: A multi-scale neural network for end-to-end audio source separation},
  author={Stoller, Daniel and Ewert, Sebastian and Dixon, Simon},
  journal={arXiv preprint arXiv:1806.03185},
  year={2018}
}

@article{nugraha2016multichannel,
  title={Multichannel audio source separation with deep neural networks},
  author={Nugraha, Aditya Arie and Liutkus, Antoine and Vincent, Emmanuel},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={24},
  number={9},
  pages={1652--1664},
  year={2016},
  publisher={IEEE}
}

@inproceedings{li2021sams,
  title={Sams-net: A sliced attention-based neural network for music source separation},
  author={Li, Tingle and Chen, Jiawei and Hou, Haowen and Li, Ming},
  booktitle={2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)},
  pages={1--5},
  year={2021},
  organization={IEEE}
}

@inproceedings{chandna2017monoaural,
  title={Monoaural audio source separation using deep convolutional neural networks},
  author={Chandna, Pritish and Miron, Marius and Janer, Jordi and G{\'o}mez, Emilia},
  booktitle={Latent Variable Analysis and Signal Separation: 13th International Conference, LVA/ICA 2017, Grenoble, France, February 21-23, 2017, Proceedings 13},
  pages={258--266},
  year={2017},
  organization={Springer}
}

@article{choi2019investigating,
  title={Investigating u-nets with various intermediate blocks for spectrogram-based singing voice separation},
  author={Choi, Woosung and Kim, Minseok and Chung, Jaehwa and Lee, Daewon and Jung, Soonyoung},
  journal={arXiv preprint arXiv:1912.02591},
  year={2019}
}

@inproceedings{takahashi2018phasenet,
  title={PhaseNet: Discretized Phase Modeling with Deep Neural Networks for Audio Source Separation.},
  author={Takahashi, Naoya and Agrawal, Purvi and Goswami, Nabarun and Mitsufuji, Yuki},
  booktitle={Interspeech},
  pages={2713--2717},
  year={2018}
}

@inproceedings{luo2018tasnet,
  title={Tasnet: time-domain audio separation network for real-time, single-channel speech separation},
  author={Luo, Yi and Mesgarani, Nima},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={696--700},
  year={2018},
  organization={IEEE}
}

@inproceedings{gan2020music,
  title={Music gesture for visual sound separation},
  author={Gan, Chuang and Huang, Deng and Zhao, Hang and Tenenbaum, Joshua B and Torralba, Antonio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10478--10487},
  year={2020}
}

@inproceedings{guso2022loss,
  title={On loss functions and evaluation metrics for music source separation},
  author={Gus{\'o}, Enric and Pons, Jordi and Pascual, Santiago and Serr{\`a}, Joan},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={306--310},
  year={2022},
  organization={IEEE}
}

@inproceedings{tzinis2020improving,
  title={Improving universal sound separation using sound classification},
  author={Tzinis, Efthymios and Wisdom, Scott and Hershey, John R and Jansen, Aren and Ellis, Daniel PW},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={96--100},
  year={2020},
  organization={IEEE}
}

@misc{mcfee_2023_8252662,
  author       = {McFee et al},
  title        = {librosa/librosa: 0.10.1},
  month        = aug,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {0.10.1},
  doi          = {10.5281/zenodo.8252662},
  url          = {https://doi.org/10.5281/zenodo.8252662}
}

@ARTICLE{vincent2006performance,
  author={Vincent, E. and Gribonval, R. and Fevotte, C.},
  journal={IEEE Transactions on Audio, Speech, and Language Processing}, 
  title={Performance measurement in blind audio source separation}, 
  year={2006},
  volume={14},
  number={4},
  pages={1462-1469},
  doi={10.1109/TSA.2005.858005}}


@inproceedings{mir_eval,
author = {Raffel, Colin and Mcfee, Brian and Humphrey, Eric and Salamon, Justin and Nieto, Oriol and Liang, Dawen and Ellis, Daniel},
year = {2014},
month = {10},
pages = {},
title = {mir\_eval: A Transparent Implementation of Common MIR Metrics},
booktitle = {Proceedings - 15th International Society for Music Information Retrieval Conference (ISMIR 2014)},
url={https://github.com/craffel/mir_eval}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011},
 url= {https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html}
}